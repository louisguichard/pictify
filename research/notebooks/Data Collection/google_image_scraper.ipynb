{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Image Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is to scrap images from Google Image using a set of search keywords.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starter(headless=False):\n",
    "\n",
    "    # Initialize driver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # Go to Google\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    # Reject cookies\n",
    "    driver.find_element(By.XPATH, \"//button[.//div[contains(text(), 'Tout refuser')]]\").click()\n",
    "\n",
    "    # Disable SafeSearch\n",
    "    driver.get(\"https://www.google.com/safesearch\")\n",
    "    driver.find_element(By.XPATH, \"//div[contains(text(), 'Désactiver')]\").click()\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url, save_path):\n",
    "    url = image_url.split(\"?\")[0]\n",
    "    extension = url.split(\".\")[-1]\n",
    "    if extension in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "        try:\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=3)\n",
    "            with open(f\"{save_path}.{extension}\", 'wb') as f:\n",
    "                f.write(response.content)\n",
    "            return True\n",
    "        except:\n",
    "            return False        \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_search(driver, keyword, category_path):\n",
    "\n",
    "    print(f\"Looking for '{keyword}' images...\")\n",
    "    url = f\"https://www.google.com/search?q={keyword.replace(' ', '+')}&tbm=isch\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Scroll down\n",
    "    for i in range(5):\n",
    "        time.sleep(5)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Find images\n",
    "    time.sleep(5)\n",
    "    images = driver.find_elements(By.XPATH, \"//div[@id='islrg']//div[@role='listitem']\")\n",
    "    print(f\"- {len(images)} images found\")\n",
    "\n",
    "    # Download images\n",
    "    idx = 0\n",
    "    for image in tqdm(images):\n",
    "        image.click()\n",
    "        image_details = driver.find_elements(By.XPATH, \"//img[@jsname='kn3ccd']\")\n",
    "        if len(image_details) == 1:\n",
    "            image_url = image_details[0].get_attribute(\"src\")\n",
    "            success = download_image(\n",
    "                image_url=image_url, \n",
    "                save_path=f\"{category_path}/{keyword.replace(' ', '_')}_{idx}\")\n",
    "            if success:\n",
    "                idx += 1\n",
    "\n",
    "    print(f\"{idx + 1} images downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 30\n",
      "Number of search keywords: 122\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = \"../../data/google_image/\"\n",
    "\n",
    "with open(\"keywords/google_image_keywords.json\") as f:\n",
    "    keywords = json.load(f)\n",
    "\n",
    "print(f\"Number of classes: {len(keywords)}\")\n",
    "print(f\"Number of search keywords: {len([search for category in keywords.values() for search in category])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class traveling ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'travel luggage' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:40<00:00,  1.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 images downloaded.\n",
      "Looking for 'packing bags' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [07:01<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class working ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'working' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [10:00<00:00,  1.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "353 images downloaded.\n",
      "Looking for 'computer' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [09:40<00:00,  1.45s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "342 images downloaded.\n",
      "Looking for 'work meeting' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:37<00:00,  1.29s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360 images downloaded.\n",
      "Looking for 'work office' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [08:48<00:00,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 images downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Very long!\n",
    "driver = starter(headless=True)\n",
    "\n",
    "for category in keywords:\n",
    "    \n",
    "    print(f\"\\n¤ ¤ ¤ ¤ ¤ Class {category} ¤ ¤ ¤ ¤ ¤\")\n",
    "    \n",
    "    # Creates category folder\n",
    "    category_path = IMAGE_PATH + category\n",
    "    if not os.path.exists(category_path):\n",
    "        os.makedirs(category_path)\n",
    "    \n",
    "    # Download images\n",
    "    for keyword in keywords[category]:\n",
    "        keyword_search(driver, keyword, category_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
