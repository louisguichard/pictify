{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Google Image Scraper"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*This notebook is to scrap images from Google Image using a set of search keywords.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.by import By\n",
    "from webdriver_manager.chrome import ChromeDriverManager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def starter(headless=False):\n",
    "    \"Initialize the web-driver\"\n",
    "\n",
    "    # Initialize driver\n",
    "    service = Service(ChromeDriverManager().install())\n",
    "    options = Options()\n",
    "    if headless:\n",
    "        options.add_argument(\"--headless\")\n",
    "    driver = webdriver.Chrome(service=service, options=options)\n",
    "    driver.implicitly_wait(5)\n",
    "\n",
    "    # Go to Google\n",
    "    driver.get(\"https://www.google.com\")\n",
    "\n",
    "    # Reject cookies\n",
    "    driver.find_element(By.XPATH, \"//button[.//div[contains(text(), 'Tout refuser')]]\").click()\n",
    "\n",
    "    # Disable SafeSearch\n",
    "    driver.get(\"https://www.google.com/safesearch\")\n",
    "    driver.find_element(By.XPATH, \"//div[contains(text(), 'Désactiver')]\").click()\n",
    "    \n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_image(image_url, save_path):\n",
    "    \"Download an image from its URL\"\n",
    "    \n",
    "    url = image_url.split(\"?\")[0]\n",
    "    extension = url.split(\".\")[-1]\n",
    "    if extension in [\"jpg\", \"jpeg\", \"png\"]:\n",
    "        try:\n",
    "            response = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=1)\n",
    "            image = Image.open(BytesIO(response.content))\n",
    "            resized_image = image.resize((500, 500))\n",
    "            resized_image.save(f\"{save_path}.{extension}\")\n",
    "            return True\n",
    "        except:\n",
    "            return False\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_keyword_images(driver, keyword, category_path):\n",
    "    \"Download images based on a keyword search\"\n",
    "\n",
    "    print(f\"Looking for '{keyword}' images...\")\n",
    "    url = f\"https://www.google.com/search?q={keyword.replace(' ', '+')}&tbm=isch\"\n",
    "    driver.get(url)\n",
    "\n",
    "    # Scroll down\n",
    "    for i in range(5):\n",
    "        time.sleep(5)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "\n",
    "    # Find images\n",
    "    time.sleep(5)\n",
    "    images = driver.find_elements(By.XPATH, \"//div[@id='islrg']//div[@role='listitem']\")\n",
    "    print(f\"- {len(images)} images found\")\n",
    "\n",
    "    # Download images\n",
    "    idx = 0\n",
    "    for image in tqdm(images):\n",
    "        image.click()\n",
    "        image_details = driver.find_elements(By.XPATH, \"//img[@jsname='kn3ccd']\")\n",
    "        if len(image_details) == 1:\n",
    "            image_url = image_details[0].get_attribute(\"src\")\n",
    "            success = download_image(\n",
    "                image_url=image_url, \n",
    "                save_path=f\"{category_path}/{keyword.replace(' ', '_')}_{idx}\")\n",
    "            if success:\n",
    "                idx += 1\n",
    "\n",
    "    print(f\"{idx + 1} images downloaded.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of classes: 30\n",
      "Number of search keywords: 122\n"
     ]
    }
   ],
   "source": [
    "IMAGE_PATH = \"../../data/google_image/\"\n",
    "\n",
    "# Load keywords\n",
    "with open(\"keywords/google_image_keywords.json\") as f:\n",
    "    keywords = json.load(f)\n",
    "\n",
    "print(f\"Number of classes: {len(keywords)}\")\n",
    "print(f\"Number of search keywords: {len([search for category in keywords.values() for search in category])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class reading ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'book' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:12<00:00,  2.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 images downloaded.\n",
      "Looking for 'books' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [14:52<00:00,  2.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "330 images downloaded.\n",
      "Looking for 'book reading' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [16:17<00:00,  2.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "308 images downloaded.\n",
      "Looking for 'home library' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:26<00:00,  2.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "333 images downloaded.\n",
      "Looking for 'reading ebook' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:38<00:00,  2.35s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310 images downloaded.\n",
      "Looking for 'magazines' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:00<00:00,  2.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "335 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class running ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'running' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:05<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311 images downloaded.\n",
      "Looking for 'running shoes' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [11:06<00:00,  1.67s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "326 images downloaded.\n",
      "Looking for 'running gear' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 80/400 [03:22<13:42,  2.57s/it]/Users/louisguichard/anaconda3/envs/pictify_env/lib/python3.10/site-packages/PIL/TiffImagePlugin.py:866: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 2. \n",
      "  warnings.warn(str(msg))\n",
      "100%|██████████| 400/400 [15:05<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298 images downloaded.\n",
      "Looking for 'running equipment' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:56<00:00,  2.39s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class sport ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'amateur soccer' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [16:51<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "271 images downloaded.\n",
      "Looking for 'badminton' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [16:52<00:00,  2.53s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "302 images downloaded.\n",
      "Looking for 'padel tennis' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:21<00:00,  2.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337 images downloaded.\n",
      "Looking for 'tennis' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [15:02<00:00,  2.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "296 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class train ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'in a train' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:21<00:00,  2.60s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288 images downloaded.\n",
      "Looking for 'train view window' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [16:05<00:00,  2.41s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281 images downloaded.\n",
      "Looking for 'train seat window' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:59<00:00,  2.70s/it] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "245 images downloaded.\n",
      "Looking for 'train station' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [18:53<00:00,  2.83s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "294 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class traveling ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'travel luggage' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [13:57<00:00,  2.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "299 images downloaded.\n",
      "Looking for 'packing bags' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [11:59<00:00,  1.80s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 images downloaded.\n",
      "\n",
      "¤ ¤ ¤ ¤ ¤ Class working ¤ ¤ ¤ ¤ ¤\n",
      "Looking for 'working' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [14:48<00:00,  2.22s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327 images downloaded.\n",
      "Looking for 'computer' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [21:07<00:00,  3.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "252 images downloaded.\n",
      "Looking for 'work meeting' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:15<00:00,  2.59s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "315 images downloaded.\n",
      "Looking for 'work office' images...\n",
      "- 400 images found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 400/400 [17:45<00:00,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "312 images downloaded.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Very long!\n",
    "driver = starter(headless=True)\n",
    "\n",
    "for category in keywords:\n",
    "    \n",
    "    print(f\"\\n¤ ¤ ¤ ¤ ¤ Class {category} ¤ ¤ ¤ ¤ ¤\")\n",
    "    \n",
    "    # Creates category folder\n",
    "    category_path = IMAGE_PATH + category\n",
    "    if not os.path.exists(category_path):\n",
    "        os.makedirs(category_path)\n",
    "    \n",
    "    # Download images\n",
    "    for keyword in keywords[category]:\n",
    "        download_keyword_images(driver, keyword, category_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
